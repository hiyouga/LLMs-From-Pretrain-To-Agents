% Part 2: Improving Model Capabilities
\section{Improving Model Capabilities}

\begin{frame}
\frametitle{Pre-training: Foundation Building}
\begin{itemize}
    \item Autoregressive pre-training objective:
    \begin{equation*}
    \mathcal{L}_{\text{AR}} = -\sum_{t=1}^{T} \log P(x_t | x_{<t}; \theta)
    \end{equation*}
    \item \textbf{Data is the core of pre-training}
    \item Evolution from weak to strong:
    \begin{itemize}
        \item Internet corpus $\rightarrow$ Large-scale synthetic data
    \end{itemize}
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{EasyDataset}
\begin{center}
Extracting synthetic data from corpus using modern models
\vspace{0.3cm}

\includegraphics[width=0.9\textwidth]{images/easydataset_framework.png}
\end{center}
\end{frame}

\begin{frame}
\frametitle{DataFlow}
\begin{center}
Automated data workflow for large language models
\vspace{0.3cm}

\includegraphics[width=0.9\textwidth]{images/dataflow_framework.png}
\end{center}
\end{frame}

\begin{frame}
\frametitle{Post-training: Alignment and Specialization}
\begin{itemize}
    \item Traditional three-stage pipeline:
    \begin{itemize}
        \item SFT $\rightarrow$ RM $\rightarrow$ RLHF
    \end{itemize}
    \item Evolution to modern approaches:
    \begin{itemize}
        \item Cold-start methods
        \item RLVR (Reinforcement Learning from Verification and Reasoning)
    \end{itemize}
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{LlamaFactory}
\begin{center}
Unified post-training framework supporting 100+ models with efficient training
\vspace{0.3cm}

\includegraphics[width=0.9\textwidth]{images/llamafactory_framework.png}
\end{center}
\end{frame}

\begin{frame}
\frametitle{Multimodal Alignment}
\begin{itemize}
    \item \textbf{Multimodal Understanding}:
    \begin{itemize}
        \item Images, videos, audio
    \end{itemize}
    \item \textbf{Multimodal Generation}:
    \begin{itemize}
        \item Text-to-image, text-to-video, text-to-audio
    \end{itemize}
    \item \textbf{Unified Understanding and Generation Models}:
    \begin{itemize}
        \item End-to-end multimodal systems
    \end{itemize}
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{VeOmni}
\begin{center}
Native tri-modal distributed training framework with decoupled 3D parallelism supporting diverse GPU hardware
\vspace{0.3cm}

\includegraphics[width=0.9\textwidth]{images/veomni_framework.png}
\end{center}
\end{frame}

\begin{frame}
\frametitle{Training Infrastructure}
\begin{itemize}
    \item \textbf{3D Parallelism Evolution}:
    \begin{itemize}
        \item Megatron: DP + TP + PP
        \item Modern: FSDP + SP + EP
    \end{itemize}
    \item \textbf{Optimization techniques}:
    \begin{itemize}
        \item Mixed precision: FP16, BF16 $\rightarrow$ FP8, FP4
        \item Gradient accumulation and recomputation
        \item High-performance operators: Flash Attention, Triton, DeepEP, Linear Attention
        \item Distributed optimizers
    \end{itemize}
\end{itemize}
\end{frame}

\begin{frame}
\begin{center}
\includegraphics[width=0.9\textwidth]{images/efficient_training.png}
\end{center}
\end{frame}

\begin{frame}
\frametitle{Inference Infrastructure}
\begin{itemize}
    \item \textbf{Key frameworks}: vLLM, SGLang
    \item \textbf{Core technologies}:
    \begin{itemize}
        \item Paged Attention
        \item Continuous batching
        \item PD separation (Prefill-Decode)
        \item AF separation (Attention-FFN)
        \item Model parallelism
        \item Quantization
        \item Speculative decoding
        \item MTP (Multi-Token Prediction)
    \end{itemize}
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{Reinforcement Learning in LLMs}
\begin{itemize}
    \item \textbf{Example: Playing card game (DouDiZhu)}
    \item \textbf{Trajectory sampling}: Play one complete game
    \item \textbf{Environment feedback}: Win or lose
    \item \textbf{Advantage function}: Game review and analysis
    \item \textbf{Policy update}: Adjust strategy for next game
\end{itemize}
\end{frame}

\begin{frame}
\begin{center}
\includegraphics[width=0.9\textwidth]{images/rl_algorithms.png}
\end{center}
\end{frame}

\begin{frame}
\frametitle{VeRL}
\begin{center}
Reinforcement learning training framework for LLMs with parallel training and inference acceleration
\vspace{0.3cm}

\includegraphics[width=0.9\textwidth]{images/verl_framework.png}
\end{center}
\end{frame}

\begin{frame}
\begin{center}
\includegraphics[width=0.9\textwidth]{images/reasoning_models.png}
\end{center}
\end{frame}
